name "rover_localization"
# Optionally declare the version number
# version "0.1"

# If new data types need to be defined, they have to be put in a separate C++
# header, and this header will be loaded here
using_library "localization" # Localization library
#using_library 'envire' # Maps and environment representation

# If the component/deployments use data types that are defined in other oroGen
# projects, these projects should be imported there as well.
import_types_from "base"
import_types_from 'sysmon'
import_types_from "torque_estimator"
#import_types_from 'envire'

import_types_from "FrontEndTypes.hpp"
import_types_from "BackEndTypes.hpp"

# It processes the sensor values to facilitate data association
task_context "Processing" do


    #*************************
    #**** Task Properties ****
    #*************************
    property('configuration', 'rover_localization/Configuration').
        doc 'General configuration values to run the task'

    #******************************
    #**** Location Properties *****
    #******************************
    property('location',"rover_localization/LocationConfiguration").
        doc 'Localization properties related to the geographic place (i.e.: latitude, longitude, magnetic declination).'

    #******************************
    #**** Rover Properties ********
    #******************************
    property('camera_synch', 'rover_localization/CameraSynchConfiguration').
        doc 'Configuration values for a sweeping camera on a robot.'

    #******************************
    #******* Input ports  *********
    #******************************

    #******* Proprioceptive sensors *********
    input_port('encoder_samples', '/base/actuators/Status').
        needs_reliable_connection.
	doc 'timestamped Motorstate samples providing odometry information.'

    input_port('systemstate_samples', '/sysmon/SystemStatus').
        needs_reliable_connection.
        doc 'timestamped systemstate readings, used for the passive joint encoder.'

    input_port('inertial_samples', '/base/samples/IMUSensors').
        needs_reliable_connection.
        doc 'provides timestamped IMUReading samples containing the calibrated sensor readings (linear acceleration and angular velocity).'

    input_port("torque_samples", "torque_estimator/WheelTorques").
        doc "Estimated torque values"

    input_port("ground_forces_samples", "torque_estimator/GroundForces").
        doc "Estimated ground force values"

    #*******  Exteroceptive sensors *********
    input_port("left_frame", ro_ptr('base::samples::frame::Frame')).
        doc 'Left camera frame.'

    input_port("right_frame", ro_ptr('base::samples::frame::Frame')).
        doc 'Right camera frame.'

    input_port('scan_samples', '/base/samples/LaserScan').
	doc 'timestamped laser scans'

    #******* External Ground Truth *********
    input_port("reference_pose_samples", "/base/samples/RigidBodyState").
        doc "Rover position and orientation information."

    #******* State information *********
    input_port('state_estimation_samples', 'rover_localization/StateEstimation').
        needs_reliable_connection.
	doc 'State estimation information.'

    ##############################################
    # Transformer:
    # All robot transformations are required
    # to compute the sensor output in body frame.
    # It uses the iMoby convention with is:
    # imu to body transformation is imu expressed in
    # body frame.
    ##############################################
    transformer do
	transform "imu", "body" #body to imu in transformation convention
	transform "reference", "body"
        transform "lcamera", "body"
        transform "laser", "body"
	align_port("encoder_samples", 0.001)
	align_port("inertial_samples", 0.002)
	align_port("systemstate_samples", 0.01)
	align_port("torque_samples", 0.01)
	align_port("ground_forces_samples", 0.01)
	align_port("left_frame", 0.5)
	align_port("right_frame", 0.5)
	align_port("scan_samples", 0.025)
	align_port("reference_pose_samples", 0.01)
	max_latency(1.0)
    end

    #******************************
    #******* Output Ports *********
    #******************************

    output_port('joints_samples_out', '/base/samples/Joints').
	doc 'Timestamped joints (active and passive) state samples providing odometry information.'+
        '[passive, rear_left_wheel, rear_right_wheel, front_right_wheel, front_left_wheel]'

    output_port('inertial_samples_out', '/base/samples/IMUSensors').
	doc 'Calibrated and compensated inertial measurements.'

    output_port('inertial_state_out', 'rover_localization/InertialState').
	doc 'Useful information related inertial samples.'

    output_port('point_cloud_samples_out', 'base/samples/Pointcloud').
	doc 'Point cloud samples.'

    output_port("left_frame_out", ro_ptr('base::samples::frame::Frame')).
        doc 'Left camera frame (after synchronization with the dynamixel)'

    output_port("right_frame_out", ro_ptr('base::samples::frame::Frame')).
        doc 'Right camera frame (after synchronization with the dynamixel).'

    output_port('reference_pose_samples_out', 'base/samples/RigidBodyState').
	doc 'Pose and velocities computed by the ground truth system.'

    output_port('reference_delta_pose_samples_out', 'base/samples/RigidBodyState').
	doc 'Delta pose and velocities computed from the ground truth system.'

    output_port('world_to_navigation_out', 'base/samples/RigidBodyState').
	doc 'Transformation: navigation frame expressed in the world frame.'


    #**********************************
    #******* Output Debug Ports *******
    #**********************************
    property('output_debug', 'bool', false).
	doc 'Set to true if output debug information is desirable.'

    output_port('angular_position', 'double').
	doc 'Angular position of the FL wheel'

    output_port('angular_rate', 'double').
	doc 'Angular velocity of the FL wheel'

    output_port('angular_rate_old', 'double').
	doc 'Angular velocity of the FL wheel(using 2nd order)'

    output_port('body_to_laser', 'base/samples/RigidBodyState').
	doc 'Body to Laser transformation: laser frame expressed with respect to the body frame. Tbody2laser'

    output_port('body_to_lcamera', 'base/samples/RigidBodyState').
	doc 'Body to Left Camera transformation : left camera frame expressed with respect to the body frame. Tbody2lcamera'

    output_port('body_to_lcamera_euler', 'base/Vector3d')
	doc 'Body to Laser transformation: laser frame expressed with respect to the body frame in Euler angles.'

    output_port('error_body_to_lcamera_euler', 'base/Vector3d')
	doc 'Body to Left Camera transformation: left camera frame expressed with respect to the body frame in Euler angles.'

    port_driven

end

# Declare the  State Optimization class
task_context "StateOptimize" do

    #**************************
    #***** Task Properties ****
    #**************************
    property('configuration', 'rover_localization/StateOptimizeConfig').
        doc 'General configuration values to run the task'

    property('adaptive_config', 'rover_localization/AdaptiveAttitudeConfig').
        doc 'Adaptive estimation of external acceleration.'

    #*********************************
    #**** Measurements Properties ****
    #*********************************
    property('inertial_noise','rover_localization/InertialNoiseProperties').
        doc 'Proprioceptive Sensors property.'

    #******************************
    #******* Input ports  *********
    #******************************
    input_port('pose_samples', '/base/samples/RigidBodyState').
        needs_reliable_connection.
        doc 'Odometry estimated robot pose (Odometry => Statistical Motion Model + IMU orientation).'

    input_port('inertial_samples', '/base/samples/IMUSensors').
        needs_reliable_connection.
        doc 'Calibrated and compensated inertial values.'

    input_port('inertial_state', 'rover_localization/InertialState').
	doc 'Useful information related inertial samples.'

    input_port('exteroceptive_samples', '/base/samples/RigidBodyState')
        doc 'Exteroceptive update samples to correct the prediction (Visual, ICP, etc..).'

    ##########################
    # Transformer
    ##########################
    transformer do
	align_port("pose_samples", 0.01)
	align_port("inertial_samples", 0.01)
	align_port("inertial_state", 0.01)
        align_port("exteroceptive_samples", 0.01)
	max_latency(0.5)
    end

    #******************************
    #******* Output ports  ********
    #******************************
    output_port('pose_samples_out', '/base/samples/RigidBodyState').
	doc 'Corrected estimated robot pose.'

   output_port('pose_error_samples_out', '/base/samples/RigidBodyState').
	doc 'Estimated pose error samples'

    output_port('state_estimation_samples_out', 'rover_localization/StateEstimation').
	doc 'State estimation information.'

    port_driven

end


