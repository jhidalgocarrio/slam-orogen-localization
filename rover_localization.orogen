name "rover_localization"
# Optionally declare the version number
# version "0.1"

# If new data types need to be defined, they have to be put in a separate C++
# header, and this header will be loaded here
# import_types_from "asguard_localizationType.hpp"
using_library "asguard" #for the asguard dedicated Kinematics and types
using_library "odometry" #for the motion model
using_library "rover_localization" #for the library of the framework
#using_library 'envire' #for the maps and visualization

# If the component/deployments use data types that are defined in other oroGen
# projects, these projects should be imported there as well.
import_types_from "base"
import_types_from 'sysmon'
import_types_from "asguard"
import_types_from "torque_estimator"
#import_types_from 'envire'
import_types_from "rover_localization/DataTypes.hpp"
import_types_from "FrameworkTypes.hpp"

# Declare the Framework FrontEnd class
# The Front-End read sensor values, creates Data association
# and generates the decision for the context-base approach
#
# The corresponding C++ class can be edited in tasks/FrontEnd.hpp and
# tasks/FrontEnd.cpp, and will be put in the rover_localization namespace.
task_context "FrontEnd" do

    #******************************
    #**** Location Properties *****
    #******************************
    property('location',"rover_localization/LocationConfiguration").
        doc 'Localization properties related to the geographic place (i.e: latitudem longitude, magnetic declination).'+
            'Look in FrameworkTypes for further details'

    #*************************************
    #**** Inertial Sensor Properties *****
    #*************************************
    property('proprioceptive_sensors','rover_localization/ProprioceptiveSensorProperties').
        doc 'Proprioceptive Sensors property. It contains the inertial and encoder sensor characterization.'+
            'Look in FrameworkTypes for further details'


    #*************************************************
    #**** Eccentricity of the IMU mounted on the robot
    #*************************************************
    property("eccx", "/base/Vector3d").
	doc "Eccentricity (in meters) for X-axis Acc in IMU frame (with respect to the IMU reference frame)."
    property("eccy", "/base/Vector3d").
	doc "Eccentricity (in meters) for Y-axis Acc in IMU frame (with respect to the IMU reference frame)."
    property("eccz", "/base/Vector3d").
	doc "Eccentricity (in meters) for Z-axis Acc in IMU frame (with respect to the IMU reference frame)."


    #******************************
    #**** Rover Properties ********
    #******************************
    property('q_weight_distribution', '/base/Quaterniond').
	doc 'Quaternion to specify the projection of the center of mass to the rover X-Y plane (center of gravity).' +
	    'Identity quaternion means the weight is equally distributed.'

    #******************************
    #**** Framework Properties ****
    #******************************
    property('framework', 'rover_localization/FrameworkConfiguration').
        doc 'Initial configuration values to run the framework. Look in FrameworkTypes for further details.'

    #******************************
    #******* Input ports  *********
    #******************************

    #******* Initial pose/External Ground Truth*********
    input_port("reference_pose_samples", "/base/samples/RigidBodyState").
        doc "Rover position and orientation information (only for initialization or debug purpose)."

    #******* Proprioceptive sensors *********
    input_port('inertial_samples', '/base/samples/IMUSensors').
        needs_reliable_connection.
        doc 'provides timestamped IMUReading samples containing the calibrated sensor readings (linear acceleration and angular velocity).'

    input_port("torque_samples", "torque_estimator/WheelTorques").
        doc "Estimated torque values"

    input_port("ground_forces_samples", "torque_estimator/GroundForces").
        doc "Estimated ground force values"

    input_port('systemstate_samples', '/sysmon/SystemStatus').
        needs_reliable_connection.
        doc 'timestamped systemstate readings, used for the passive joint encoder'

    input_port('encoder_samples', '/base/actuators/Status').
        needs_reliable_connection.
	doc 'timestamped Motorstate samples providing odometry information.'

    input_port('backend_estimation_samples', 'rover_localization/BackEndEstimation').
        needs_reliable_connection.
	doc 'Back-End filtering estimation information (feedback).'


    #******* Exteroceptive sensors *********
    #TO-DO

    ##########################
    # Transformer
    ##########################
    transformer do
	transform "imu", "body"
	align_port("inertial_samples", 0.002)
	align_port("encoder_samples", 0.001)
	align_port("systemstate_samples", 0.01)
	align_port("torque_samples", 0.01)
	align_port("ground_forces_samples", 0.01)
	transform "vicon", "body"
	align_port("reference_pose_samples", 0.01)
	align_port("backend_estimation_samples", 0.01)
	max_latency(0.5)
    end

    #******************************
    #******* Output Ports *********
    #******************************
    output_port('pose_samples_out', '/base/samples/RigidBodyState').
	doc 'Estimated rover pose. Position and velocity is computed from statistical Motion Model.'+
            'Orientation from IMU gyros integration.'

    output_port('inertial_samples_out', 'rover_localization/InertialState').
	doc 'Corrected proprioceptive inertial samples to connect to the backend.'

    output_port('reference_pose_samples_out', 'base/samples/RigidBodyState').
	doc 'Pose and velocities computed by the ground truth system but in the correct frame.'

    output_port('incre_reference_pose_samples_out', 'base/samples/RigidBodyState').
	doc 'Delta pose and velocities computed from the ground truth system.'

    output_port('fkchains_samples_out', 'rover_localization/RobotContactPoints').
        doc 'Position and orientation of Contact points frame of the robot wrt the Body center'


    #******************************
    #******* Debug OutPorts *******
    #******************************
    output_port('slip_vector', '/localization/SlipInfo').
	doc 'Timestamped slip vector for the rover (all the wheels)'

    output_port('velocities_model', 'base/samples/RigidBodyState').
	doc 'Linear velocities computed by the model'

    output_port('velocities_corrected', 'base/samples/RigidBodyState').
	doc 'Corrected rover linear velocities'

    output_port('incre_velocities_imu', 'base/samples/RigidBodyState').
	doc 'Linear velocities computed by the inertial sensors'

    output_port('incre_velocities_model', 'base/samples/RigidBodyState').
	doc 'Incremental linear velocities computed by the model'

    output_port('incre_velocities_error', 'base/samples/RigidBodyState').
	doc 'Incremental velocity error in body frame'

    output_port('velocities_error', 'base/samples/RigidBodyState').
	doc 'Velocity error in body frame'

    output_port('velocities_error_truth', 'base/samples/RigidBodyState').
	doc 'Velocity error in body frame comparison with the vicon system'

    output_port('imu_sensors_out', '/base/samples/IMUSensors').
	doc 'Inertial sensor outport processed by the callback function of the transformer'

    output_port('debug_info', '/localization/UtilInfo').
	doc 'Some debug information of the least-squares computation.'

    output_port('angular_position', 'double').
	doc 'Angular position of the FL wheel'

    output_port('angular_rate', 'double').
	doc 'Angular velocity of the FL wheel'

    output_port('angular_rate_old', 'double').
	doc 'Angular velocity of the FL wheel(using 2nd order)'

    port_driven

end

# Declare the Framework BackEnd class
# The BackEnd comprises the optimal state estimator preferable in an indirect form,
# either using recursive non-linear least-squares (kalman-form), or
# non-parametric filters (bayesian, particle form).
#
# The corresponding C++ class can be edited in tasks/BackEnd.hpp and
# tasks/BackEnd.cpp, and will be put in the rover_localization namespace.
task_context "BackEnd" do

    #************************************
    #**** Inertial Sensor Properties ****
    #************************************
    property('proprioceptive_sensors','rover_localization/ProprioceptiveSensorProperties').
        doc 'Proprioceptive Sensors property. It contains the inertial and encoder sensor characterization.'+
            'Look in FrameworkTypes for further details'

    #*****************************
    #***** BackEnd Properties ****
    #*****************************
    property('framework', 'rover_localization/FrameworkConfiguration').
        doc 'Initial configuration values to run the framework. Look in FrameworkTypes for further details.'

    property('adaptive_filter', 'rover_localization/AdaptiveMeasurementProperties').
        doc 'Properties for the adaptive estimation of external acceleration. Look in FrameworkTypes for further details.'

    #******************************
    #******* Input ports  *********
    #******************************
    input_port('pose_samples', '/base/samples/RigidBodyState').
        doc 'Front-End estimated rover pose (Odometry => Statistical Motion Model + IMU orientation)'

    input_port('inertial_samples', 'rover_localization/InertialState').
	doc 'Corrected proprioceptive inertial samples to predict backend uncertainty.'

    input_port('exteroceptive_samples', '/base/samples/RigidBodyState')
        doc 'Exteroceptive update samples to correct the prediction (Visual, ICP, etc..).'

    input_port('update_samples', '/base/samples/RigidBodyState').
        doc 'Proprioceptive update samples to correct the prediction.'

    ##########################
    # Transformer
    ##########################
    transformer do
	align_port("pose_samples", 0.01)
	align_port("inertial_samples", 0.01)
        align_port("exteroceptive_samples", 0.01)
	align_port("update_samples", 0.01)
	max_latency(0.5)
    end

    #******************************
    #******* Output ports  ********
    #******************************
    output_port('error_samples_out', '/base/samples/RigidBodyState').
	doc 'Estimated pose error samples'

    output_port('pose_samples_out', '/base/samples/RigidBodyState').
	doc 'Corrected estimated robot pose'

    output_port('backend_estimation_samples_out', 'rover_localization/BackEndEstimation').
	doc 'Back-End filtering estimation information (feedback).'


    port_driven

end


# Declare the Visualization class
# The Visualization comprises all the stuffs related to visualize it in vizkit
#
# The corresponding C++ class can be edited in tasks/Visualization.hpp and
# tasks/Visualization.cpp, and will be put in the rover_localization namespace.
task_context "Visualization" do

    #***************************************************
    #***** Visualization Properties (as Input Port)*****
    #**************************8************************
    input_port('framework', 'rover_localization/FrameworkConfiguration').
        doc 'Initial configuration values to run the framework. Look in FrameworkTypes for further details.'

    #*************************************
    #**** Input Visualization Ports ******
    #*************************************
    input_port('frontend_pose_samples', '/base/samples/RigidBodyState').
	doc 'Estimated robot pose from front-end'

    input_port('backend_pose_samples', '/base/samples/RigidBodyState').
	doc 'Corrected estimated robot pose from back-end'

    input_port('reference_pose_samples', '/base/samples/RigidBodyState').
	doc 'Ground truth robot pose (if available).'

    input_port('fkchains_samples', 'rover_localization/RobotContactPoints').
        doc 'position and orientation of Contact points frame of the robot wrt the Body center'

    ##########################
    # Transformer
    ##########################
    transformer do
	align_port("frontend_pose_samples", 0.01)
	align_port("backend_pose_samples", 0.1)
        align_port("reference_pose_samples", 0.01)
	align_port("fkchains_samples", 0.01)
	max_latency(0.5)
    end

    #*************************************
    #**** Output Visualization Ports *****
    #*************************************

    # BODY CENTER
    output_port('frontend_pose_samples_out', '/base/samples/RigidBodyState').
	doc 'Estimated robot pose from front-end'

    output_port('backend_pose_samples_out', '/base/samples/RigidBodyState').
	doc 'Corrected estimated robot pose from back-end'

    output_port('reference_pose_samples_out', '/base/samples/RigidBodyState').
	doc 'Ground truth robot pose (if available).'

    # DEDICATED TYPES
    output_port('bodystate_samples_out', '/asguard/BodyState').
	doc 'timestamped asguard bodystate information'

    # FROWARD KINEMATICS RIGID BODY STATE
    output_port('fkchains_rbs_out', 'rover_localization/RobotContactPointsRbs').
        doc 'Rigid Body States with the position and orientation of Contact points frame'+
            'of the robot wrt the world frame'

    port_driven
end


